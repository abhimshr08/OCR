{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT9Sjkd3tqW4LoIDaJuSdf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhimshr08/OCR/blob/main/OCR_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KkMz2rx_wMh"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import re\n",
        "import base64\n",
        "import requests\n",
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "from IPython.display import display, HTML, Audio\n",
        "from google.colab import files\n",
        "from getpass import getpass\n",
        "from tqdm.notebook import tqdm\n",
        "from termcolor import colored\n",
        "import os\n",
        "import traceback\n",
        "import json\n",
        "import ast\n",
        "\n",
        "def cprint(msg, state='info'):\n",
        "    icons = {'info': 'üî∑', 'success': '‚úÖ', 'error': '‚ùå', 'debug': 'üëÄ', 'warn': '‚ö†Ô∏è'}\n",
        "    colors = {'info': 'cyan', 'success': 'green', 'error': 'red', 'debug': 'magenta', 'warn': 'yellow'}\n",
        "    print(colored(f\"{icons.get(state, '‚ÑπÔ∏è')} {msg}\", colors.get(state, 'cyan')))\n",
        "\n",
        "cprint(\"Please upload your CSV (1st column should have Google Drive links):\", 'info')\n",
        "uploaded = files.upload()\n",
        "csv_path = next(iter(uploaded))\n",
        "cprint(\"Now, please enter your OpenAI API Key (input box below is HIDDEN):\", 'info')\n",
        "openai.api_key = getpass()\n",
        "\n",
        "def extract_drive_file_id(url):\n",
        "    m = re.search(r'/d/([\\w-]+)', url)\n",
        "    if m: return m.group(1)\n",
        "    m = re.search(r'id=([\\w-]+)', url)\n",
        "    if m: return m.group(1)\n",
        "    m = re.search(r'/open\\?id=([\\w-]+)', url)\n",
        "    if m: return m.group(1)\n",
        "    return None\n",
        "\n",
        "def download_from_drive(file_id, dest):\n",
        "    cprint(f\"Downloading Google Drive file_id {file_id} ...\", 'info')\n",
        "    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    session = requests.Session()\n",
        "    response = session.get(download_url, stream=True)\n",
        "    if 'Content-Disposition' in response.headers:\n",
        "        with open(dest, \"wb\") as f:\n",
        "            for chunk in response.iter_content(1024):\n",
        "                f.write(chunk)\n",
        "        cprint(f\"File saved as {dest}\", 'debug')\n",
        "        return dest\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            params = {'id': file_id, 'confirm': value}\n",
        "            response = session.get(download_url, params=params, stream=True)\n",
        "            with open(dest, \"wb\") as f:\n",
        "                for chunk in response.iter_content(1024):\n",
        "                    f.write(chunk)\n",
        "            cprint(f\"File saved as {dest}\", 'debug')\n",
        "            return dest\n",
        "    raise Exception(\"Failed to download from Google Drive.\")\n",
        "\n",
        "def pdf_to_images(pdf_path):\n",
        "    cprint(f\"Converting PDF '{os.path.basename(pdf_path)}' to images...\", 'info')\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        image_paths = []\n",
        "        for i, image in enumerate(images):\n",
        "            img_path = f'/content/page_{i}_{os.path.basename(pdf_path)}.png'\n",
        "            image.save(img_path)\n",
        "            cprint(f\"Page {i+1}: {img_path}\", 'debug')\n",
        "            image_paths.append(img_path)\n",
        "        return image_paths\n",
        "    except Exception as e:\n",
        "        cprint(f\"PDF conversion failed: {e}\", 'error')\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "def image_to_base64(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            return base64.b64encode(image_file.read()).decode()\n",
        "    except Exception as e:\n",
        "        cprint(f\"Couldn't base64 encode image {image_path}: {e}\", 'error')\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def robust_json_extract(text):\n",
        "    \"\"\"\n",
        "    Try to extract a JSON object from model output, handling single/double quotes and some common syntax errors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        m = re.search(r\"\\{[\\s\\S]+\\}\", text)\n",
        "        if m:\n",
        "            chunk = m.group(0)\n",
        "            # Try parsing with json.loads() directly first\n",
        "            try:\n",
        "                return json.loads(chunk)\n",
        "            except Exception:\n",
        "                # Replace single quotes with double quotes for JSON\n",
        "                fixed = re.sub(r\"'\", '\"', chunk)\n",
        "                try:\n",
        "                    return json.loads(fixed)\n",
        "                except Exception:\n",
        "                    # As a last resort, use ast.literal_eval (safe for dict-like strings)\n",
        "                    try:\n",
        "                        return ast.literal_eval(chunk)\n",
        "                    except Exception:\n",
        "                        try:\n",
        "                            return ast.literal_eval(fixed)\n",
        "                        except Exception:\n",
        "                            pass\n",
        "        # If nothing works, fall back to empty dict\n",
        "        return {}\n",
        "    except Exception as exc:\n",
        "        print(f\"robust_json_extract failed: {exc}\")\n",
        "        return {}\n",
        "\n",
        "def classify_document(image_path):\n",
        "    \"\"\"Identify the document type using GPT vision.\"\"\"\n",
        "    image_b64 = image_to_base64(image_path)\n",
        "    if not image_b64:\n",
        "        return None\n",
        "    prompt = (\n",
        "        \"This is an Indian legal/official/scanned document image. \"\n",
        "        \"Classify the document type as one of the following: \"\n",
        "        \"['Aadhar Card', 'PAN Card', 'Driving License', 'Cancelled Cheque', \"\n",
        "        \"'Education Certificate', 'Degree Certificate', 'Marksheet', 'GST Certificate', \"\n",
        "        \"'Passport', 'Bank Statement', 'Passbook', 'Other']. \"\n",
        "        \"If it has a large table with transactions, bank name/logo and account info, call it 'Bank Statement' or 'Passbook'. \"\n",
        "        \"If it's a government tax certificate with GSTIN, it's a 'GST Certificate'. \"\n",
        "        \"If it has marks, grades, university/school info, or says 'degree', it's an 'Education Certificate', 'Degree Certificate', or 'Marksheet'. \"\n",
        "        \"Return strict JSON: {'type': '...'}.\"\n",
        "    )\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
        "                ]}],\n",
        "            max_tokens=100\n",
        "        )\n",
        "        text_resp = response.choices[0].message.content\n",
        "        cprint(f\"Classify raw: {text_resp}\", \"debug\")\n",
        "        data = robust_json_extract(text_resp)\n",
        "        doc_type = data.get('type', None)\n",
        "        return doc_type.strip() if doc_type else None\n",
        "    except Exception as e:\n",
        "        cprint(f\"Classification error: {e}\", 'error')\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def query_gpt_with_template(image_path, extraction_prompt):\n",
        "    \"\"\"Calls OpenAI GPT with a given prompt template for the image; expects robust JSON response\"\"\"\n",
        "    image_b64 = image_to_base64(image_path)\n",
        "    if not image_b64:\n",
        "        return {}\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": extraction_prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
        "                ]}\n",
        "            ],\n",
        "            max_tokens=400\n",
        "        )\n",
        "        text_resp = response.choices[0].message.content\n",
        "        cprint(f\"OCR raw: {text_resp}\", \"debug\")\n",
        "        return robust_json_extract(text_resp)\n",
        "    except Exception as e:\n",
        "        cprint(f\"OCR error: {e}\", 'error')\n",
        "        traceback.print_exc()\n",
        "        return {}\n",
        "\n",
        "PROMPT_TEMPLATES = {\n",
        "    \"Aadhar Card\": (\n",
        "        \"From this Indian Aadhaar card, extract as JSON: \"\n",
        "        \"{'name': ..., 'dob': ..., 'aadhar_number': ..., 'permanent_address': ...} \"\n",
        "        \"(Aadhaar number is a 12-digit number, address is under 'Address'. If a field is not present, leave blank. Use dd-mm-yyyy date format.)\"\n",
        "    ),\n",
        "    \"PAN Card\": (\n",
        "        \"From this Indian PAN card, extract as JSON: {'name': ..., 'dob': ..., 'pan_number': ...} \"\n",
        "        \"(PAN is a 10-character alphanumeric code, use dd-mm-yyyy for dob).\"\n",
        "    ),\n",
        "    \"Driving License\": (\n",
        "        \"From this Indian Driving License, extract as JSON: \"\n",
        "        \"{'dl_number': ..., 'name': ..., 'dob': ..., 'address': ...} \"\n",
        "        \"(Use dd-mm-yyyy for DOB. DL number is the driving license number.)\"\n",
        "    ),\n",
        "    \"Cancelled Cheque\": (\n",
        "        \"From this Indian cancelled cheque or bank image, extract as JSON: \"\n",
        "        \"{'bank_name': ..., 'account_holder_name': ..., 'account_number': ..., 'ifsc_code': ...} \"\n",
        "        \"Use blank for any missing fields.\"\n",
        "    ),\n",
        "    \"GST Certificate\": (\n",
        "        \"From this Indian GST Certificate, extract as JSON: \"\n",
        "        \"{'registration_number': ..., 'legal_name': ..., 'trade_name': ..., 'gst_validity': ...} \"\n",
        "        \"(Registration number is GSTIN; trade name may be blank. GST validity is the registration date or period.)\"\n",
        "    ),\n",
        "    \"Passport\": (\n",
        "        \"From this Indian Passport, extract as JSON: {'name': ..., 'dob': ...} (Use dd-mm-yyyy for dob.)\"\n",
        "    ),\n",
        "    \"Education Certificate\": (\n",
        "        \"From this Indian Education Certificate, extract as JSON: \"\n",
        "        \"{'degree_name': ..., 'learner_name': ..., 'institute_name': ..., 'year_of_passing': ...} \"\n",
        "        \"(The degree name/type, learner's name, university/board/institute name, and passing year. Leave blank if not found.)\"\n",
        "    ),\n",
        "    \"Degree Certificate\": (\n",
        "        \"From this Degree or Diploma certificate, extract as JSON: {'degree_name': ..., 'learner_name': ..., 'institute_name': ..., 'year_of_passing': ...} \"\n",
        "        \"(Degree/qualification name, student's name, university/institute, year of passing. Leave blank if not found).\"\n",
        "    ),\n",
        "    \"Marksheet\": (\n",
        "        \"From this Indian Marksheet, extract as JSON: {'learner_name': ..., 'institute_name': ..., 'exam_name': ..., 'year': ...} \"\n",
        "        \"(Exam name can be 'CBSE', 'ICSE', subject etc; year is year of examination. Leave blank if not found.)\"\n",
        "    ),\n",
        "    \"Bank Statement\": (\n",
        "        \"From this bank statement (may be first page), extract as JSON: \"\n",
        "        \"{'account_holder_name': ..., 'account_number': ..., 'bank_name': ..., 'ifsc_code': ...} \"\n",
        "        \"(These fields are usually in the header. Leave blank if not found.)\"\n",
        "    ),\n",
        "    \"Passbook\": (\n",
        "        \"From this Indian bank passbook, extract as JSON: \"\n",
        "        \"{'account_holder_name': ..., 'account_number': ..., 'bank_name': ..., 'ifsc_code': ...} \"\n",
        "        \"(Top section or table header. Leave blank if not found.)\"\n",
        "    ),\n",
        "    \"Other\": (\n",
        "        \"Extract all possible important details as JSON: \"\n",
        "        \"{'name': ..., 'dob': ..., 'aadhar_number': ..., 'pan_number': ..., 'account_number': ..., 'registration_number': ..., 'degree_name': ..., 'learner_name': ...} \"\n",
        "        \"If a field is not found, use blank.\"\n",
        "    )\n",
        "}\n",
        "\n",
        "# --- Main processing ---\n",
        "df = pd.read_csv(csv_path)\n",
        "output = []\n",
        "\n",
        "result_columns = [\n",
        "    'link', 'document_type', 'error',\n",
        "    'name', 'dob', 'aadhar_number', 'pan_number', 'permanent_address',\n",
        "    'degree_name', 'learner_name', 'institute_name', 'year_of_passing',\n",
        "    'exam_name', 'year',\n",
        "    'dl_number', 'address',\n",
        "    'bank_name', 'account_holder_name', 'account_number', 'ifsc_code',\n",
        "    'registration_number', 'legal_name', 'trade_name', 'gst_validity'\n",
        "]\n",
        "\n",
        "cprint(f\"Processing {len(df)} files...\", 'info')\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"‚è≥ Records\"):\n",
        "    cprint(f\"\\n==============\\nRecord {idx+1}/{len(df)}\", 'info')\n",
        "    drive_url = row.iloc[0] if 'link' not in row.index else row['link']\n",
        "    cprint(f\"Google Drive link: {drive_url}\", 'debug')\n",
        "\n",
        "    file_id = extract_drive_file_id(str(drive_url))\n",
        "    if not file_id:\n",
        "        cprint(\"No file ID found in link!\", 'error')\n",
        "        empty_row = {col: None for col in result_columns}\n",
        "        empty_row['link'] = drive_url\n",
        "        empty_row['error'] = 'No file id found'\n",
        "        output.append(empty_row)\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        local_path = f\"/content/file_{file_id}\"\n",
        "        download_from_drive(file_id, local_path)\n",
        "        with open(local_path, 'rb') as f:\n",
        "            header = f.read(4)\n",
        "        if header == b'%PDF':\n",
        "            images = pdf_to_images(local_path)\n",
        "        else:\n",
        "            img_ext = os.path.splitext(drive_url)[1] or '.png'\n",
        "            image_path = local_path + img_ext\n",
        "            os.rename(local_path, image_path) if not os.path.exists(image_path) else None\n",
        "            images = [image_path]\n",
        "\n",
        "        extracted = {}\n",
        "        doc_type_guess = None\n",
        "        for page_idx, img in enumerate(images):\n",
        "            cprint(f\"Processing image/page {page_idx+1} of {len(images)}...\", 'info')\n",
        "            doc_type_guess = classify_document(img)\n",
        "            cprint(f\"Classified as: {doc_type_guess}\", 'debug')\n",
        "            use_type = doc_type_guess if doc_type_guess in PROMPT_TEMPLATES else \"Other\"\n",
        "            prompt = PROMPT_TEMPLATES[use_type]\n",
        "            result = query_gpt_with_template(img, prompt)\n",
        "            if result and any(str(v).strip() for v in result.values()):\n",
        "                extracted = result\n",
        "                break\n",
        "\n",
        "        # If nothing meaningful was extracted, fallback to generic extraction\n",
        "        if not extracted or not any(str(v).strip() for v in extracted.values()):\n",
        "            generic_prompt = (\n",
        "                \"From this document, extract as JSON: \"\n",
        "                \"{'name': ..., 'dob': ..., 'aadhar_number': ..., 'pan_number': ..., 'account_number': ..., 'degree_name': ..., 'learner_name': ..., 'registration_number': ...}. \"\n",
        "                \"If not found, use blank fields.\"\n",
        "            )\n",
        "            fallback = query_gpt_with_template(images[0], generic_prompt)\n",
        "            extracted = fallback if any(str(v).strip() for v in fallback.values()) else {}\n",
        "\n",
        "        row_data = {col: '' for col in result_columns}\n",
        "        row_data['link'] = drive_url\n",
        "        row_data['document_type'] = doc_type_guess\n",
        "        row_data['error'] = None\n",
        "\n",
        "        # Populate from extracted\n",
        "        for k in row_data.keys():\n",
        "            if k in extracted and extracted[k] is not None:\n",
        "                row_data[k] = extracted[k]\n",
        "        output.append(row_data)\n",
        "        cprint(f\"RESULT ‚Üí {json.dumps(row_data, indent=2)}\", 'success')\n",
        "    except Exception as e:\n",
        "        cprint(f\"File processing failed: {e}\", 'error')\n",
        "        traceback.print_exc()\n",
        "        empty_row = {col: None for col in result_columns}\n",
        "        empty_row['link'] = drive_url\n",
        "        empty_row['error'] = str(e)\n",
        "        output.append(empty_row)\n",
        "\n",
        "result_df = pd.DataFrame(output, columns=result_columns)\n",
        "result_path = '/content/extracted_combined_info.csv'\n",
        "result_df.to_csv(result_path, index=False)\n",
        "\n",
        "cprint(\"\\n========== SUMMARY ==========\", 'info')\n",
        "\n",
        "def color_fail(val):\n",
        "    color = '#fbe7e7' if pd.isnull(val) or str(val).lower() in ('none', '') else '#bdf7b7'\n",
        "    return f'background-color: {color}'\n",
        "\n",
        "display(HTML(result_df.style.applymap(color_fail, subset=result_df.columns[2:]).set_caption(\"Extraction Results\").to_html()))\n",
        "files.download(result_path)\n",
        "cprint(\"Extraction completed üéâ. File is ready for download.\", 'success')\n",
        "\n",
        "try:\n",
        "    display(Audio(url=\"https://actions.google.com/sounds/v1/alarms/beep_short.ogg\", autoplay=True))\n",
        "except:\n",
        "    pass"
      ]
    }
  ]
}